{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Abstractive Text Summarization Using Pegasus\r\n",
    "_By: Ling Li Ya_\r\n",
    "\r\n",
    "References:\r\n",
    "1. [Exploring Pegasus - A New Text Summarization NLP Model](https://signal.onepointltd.com/post/102ghb9/exploring-pegasus-a-new-text-summarization-nlp-model)\r\n",
    "2. [Notebook referred to prepare this notebook](https://colab.research.google.com/drive/1-zq8AJktuC3gQAHTuSiiZ_qvDl4wK7rq#scrollTo=S3PYeeGuda0m)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "!pip install tensorflow"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import tensorflow as tf\r\n",
    "tf.test.gpu_device_name()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Install and Import Dependencies\r\n",
    "\r\n",
    "Install `sentencepiece` to be used as a tokenizer for the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "!pip install sentencepiece"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.1.96)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install `transformers` to use its `summarization pipeline`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "!pip install transformers"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.62.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: six in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install `bs4` to use `BeautifulSoup`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "!pip install bs4"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\liana\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import all dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, pipeline\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import torch\r\n",
    "import requests"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\liana\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchaudio\\backend\\utils.py:67: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check whether CUDA (GPU) is correctly installed on device. This is important because tensors will need to be assigned to use GPU instead of CPU. GPU is much faster than CPU in this case due to multi-threading."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check which CPU is being used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "torch.cuda.current_device()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the name of the GPU being used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import torch\r\n",
    "torch.cuda.get_device_name(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'GeForce RTX 3050 Ti Laptop GPU'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Total GPUs available on device."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "torch.cuda.device_count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Setup Generator\r\n",
    "Deifne and get model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model_name = 'google/pegasus-xsum'\r\n",
    "device = 'cuda'\r\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\r\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get pipeline text summarization utility"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Process Input Text\r\n",
    "Get input from website URLs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/Rococo'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get HTTP URL using `requests`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "r = requests.get(URL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parse HTML body returned from the URL and format it to have a better readability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "results = soup.find_all(['h1', 'p'])\r\n",
    "results[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading\" id=\"firstHeading\">Rococo</h1>,\n",
       " <p class=\"mw-empty-elt\">\n",
       " </p>,\n",
       " <p><b>Rococo</b> (<span class=\"rt-commentedText nowrap\"><span class=\"IPA nopopups noexcerpt\"><a href=\"/wiki/Help:IPA/English\" title=\"Help:IPA/English\">/<span style=\"border-bottom:1px dotted\"><span title=\"'r' in 'rye'\">r</span><span title=\"/ə/: 'a' in 'about'\">ə</span><span title=\"/ˈ/: primary stress follows\">ˈ</span><span title=\"'k' in 'kind'\">k</span><span title=\"/oʊ/: 'o' in 'code'\">oʊ</span><span title=\"'k' in 'kind'\">k</span><span title=\"/oʊ/: 'o' in 'code'\">oʊ</span></span>/</a></span></span>, <small>also</small> <span class=\"rt-commentedText nowrap\"><small><a href=\"/wiki/American_English\" title=\"American English\">US</a>: </small><span class=\"IPA nopopups noexcerpt\"><a href=\"/wiki/Help:IPA/English\" title=\"Help:IPA/English\">/<span style=\"border-bottom:1px dotted\"><span title=\"/ˌ/: secondary stress follows\">ˌ</span><span title=\"'r' in 'rye'\">r</span><span title=\"/oʊ/: 'o' in 'code'\">oʊ</span><span title=\"'k' in 'kind'\">k</span><span title=\"/ə/: 'a' in 'about'\">ə</span><span title=\"/ˈ/: primary stress follows\">ˈ</span><span title=\"'k' in 'kind'\">k</span><span title=\"/oʊ/: 'o' in 'code'\">oʊ</span></span>/</a></span></span>), less commonly <b>Roccoco</b> or <b>Late Baroque</b>, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and <i><a href=\"/wiki/Trompe-l%27%C5%93il\" title=\"Trompe-l'œil\">trompe-l'œil</a></i> frescoes to create surprise and the illusion of motion and drama.  It is often described as the final expression of the <a class=\"mw-redirect\" href=\"/wiki/Baroque_art\" title=\"Baroque art\">Baroque</a> movement.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEOwens201492_1-0\"><a href=\"#cite_note-FOOTNOTEOwens201492-1\">[1]</a></sup>\n",
       " </p>]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text enclosed within the HTML tags are selected and joined together"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "text = [result.text for result in results]\r\n",
    "ARTICLE = ' '.join(text)\r\n",
    "ARTICLE[0:1000]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Rococo \\n Rococo (/rəˈkoʊkoʊ/, also US: /ˌroʊkəˈkoʊ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'œil frescoes to create surprise and the illusion of motion and drama.  It is often described as the final expression of the Baroque movement.[1]\\n The Rococo style began in France in the 1730s as a reaction against the more formal and geometric Style Louis XIV. It was known as the style rocaille, or rocaille style.[2] It soon spread to other parts of Europe, particularly northern Italy, Austria, southern Germany, Central Europe and Russia.[3] It also came to influence the other arts, particularly sculpture, furniture, silverware, glassware, painting, music, and theatre.[4] Although originally a secular style primarily used for interiors of private residences the Rococo had a spiritual aspect to it whic\""
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "src_text = [\r\n",
    "    \"\"\"Rococo (/rəˈkoʊkoʊ/, also US: /ˌroʊkəˈkoʊ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'œil frescoes to create surprise and the illusion of motion and drama. It is often described as the final expression of the Baroque movement.[1] The Rococo style began in France in the 1730s as a reaction against the more formal and geometric Style Louis XIV. It was known as the style rocaille, or rocaille style.[2] It soon spread to other parts of Europe, particularly northern Italy, Austria, southern Germany, Central Europe and Russia.[3] It also came to influence the other arts, particularly sculpture, furniture, silverware, glassware, painting, music, and theatre.[4] Although originally a secular style primarily used for interiors of private residences the Rococo had a spiritual aspect to it which led to its widespread use in church interiors, particularly in Central Europe, Portugal, and South America.[5]\"\"\", \"\"\"The word rococo was first used as a humorous variation of the word rocaille.[6][7] Rocaille was originally a method of decoration, using pebbles, seashells and cement, which was often used to decorate grottoes and fountains since the Renaissance.[8][9] In the late 17th and early 18th century rocaille became the term for a kind of decorative motif or ornament that appeared in the late Style Louis XIV, in the form of a seashell interlaced with acanthus leaves. In 1736 the designer and jeweler Jean Mondon published the Premier Livre de forme rocquaille et cartel, a collection of designs for ornaments of furniture and interior decoration. It was the first appearance in print of the term \"rocaille\" to designate the style.[10] The carved or molded seashell motif was combined with palm leaves or twisting vines to decorate doorways, furniture, wall panels and other architectural elements.[11]\"\"\"\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Chunk text\r\n",
    "\r\n",
    "Append <eos> to punctuations that marks the end of a sentence\r\n",
    "<br />\r\n",
    "Without the <eos> tag, sentences will be split without any punctuation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "ARTICLE = ARTICLE.replace('.', '.<eos>')\r\n",
    "ARTICLE = ARTICLE.replace('!', '!<eos>')\r\n",
    "ARTICLE = ARTICLE.replace('?', '?<eos>')\r\n",
    "sentences = ARTICLE.split('<eos>')\r\n",
    "sentences[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"Rococo \\n Rococo (/rəˈkoʊkoʊ/, also US: /ˌroʊkəˈkoʊ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'œil frescoes to create surprise and the illusion of motion and drama.\",\n",
       " '  It is often described as the final expression of the Baroque movement.',\n",
       " '[1]\\n The Rococo style began in France in the 1730s as a reaction against the more formal and geometric Style Louis XIV.',\n",
       " ' It was known as the style rocaille, or rocaille style.',\n",
       " '[2] It soon spread to other parts of Europe, particularly northern Italy, Austria, southern Germany, Central Europe and Russia.',\n",
       " '[3] It also came to influence the other arts, particularly sculpture, furniture, silverware, glassware, painting, music, and theatre.',\n",
       " '[4] Although originally a secular style primarily used for interiors of private residences the Rococo had a spiritual aspect to it which led to its widespread use in church interiors, particularly in Central Europe, Portugal, and South America.',\n",
       " '[5]\\n The word rococo was first used as a humorous variation of the word rocaille.',\n",
       " '[6][7] Rocaille was originally a method of decoration, using pebbles, seashells and cement, which was often used to decorate grottoes and fountains since the Renaissance.',\n",
       " '[8][9] In the late 17th and early 18th century rocaille became the term for a kind of decorative motif or ornament that appeared in the late Style Louis XIV, in the form of a seashell interlaced with acanthus leaves.']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Limit the size of text in a chunk so that it is smaller than 500 words\r\n",
    "<br />\r\n",
    "Split sentences into words (2D array)\r\n",
    "<br />\r\n",
    "This is to avoid the error as shown below\r\n",
    "```py\r\n",
    "Token indices sequence length is longer than the specified maximum sequence length for this model (512). Running this sequence through the model will result in indexing errors.\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "max_chunk = 250\r\n",
    "current_chunk = 0\r\n",
    "chunks = []\r\n",
    "\r\n",
    "for sentence in sentences:\r\n",
    "    if len(chunks) == current_chunk + 1:\r\n",
    "        # Check if the chunk is less than 500 words\r\n",
    "        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\r\n",
    "            chunks[current_chunk].extend(sentence.split(' '))\r\n",
    "        # Next chunk\r\n",
    "        else:\r\n",
    "            current_chunk += 1\r\n",
    "            chunks.append(sentence.split(' '))\r\n",
    "    else:\r\n",
    "        print(current_chunk)\r\n",
    "        chunks.append(sentence.split(' '))\r\n",
    "\r\n",
    "print(\"A total of \" + str(current_chunk + 1) + \" chunks\")\r\n",
    "print(\"A total of \" + str(len(chunks[0])) + \" words in chunk[0]\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "A total of 26 chunks\n",
      "A total of 212 words in chunk[0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Append words into sentences again where each chunk is ensured to have less than 500 words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for chunk_id in range (len(chunks)):\r\n",
    "    chunks[chunk_id] = ' '.join(chunks[chunk_id])\r\n",
    "\r\n",
    "print(\"A total of \" + str(len(chunks[0].split(' '))) + \" words in chunk[0]\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A total of 212 words in chunk[0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Summarise Text\r\n",
    "\r\n",
    "Summarise based on each chunk"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "batch = tokenizer(chunks, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\r\n",
    "batch"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[91930, 91930,   143,  ...,     0,     0,     0],\n",
       "        [ 1126,  2000, 32887,  ...,     0,     0,     0],\n",
       "        [  139,  4234,   116,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  222,   109, 75864,  ...,     0,     0,     0],\n",
       "        [ 4648,   131,   116,  ...,  2895,   107,     1],\n",
       "        [55242,  3203, 91911,  ...,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# translated = []\r\n",
    "# for i in range(len(batch)):\r\n",
    "#     translated += model.generate(batch[i])\r\n",
    "\r\n",
    "translated = model.generate(**batch)\r\n",
    "translated"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17784/2172459746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtranslated\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# translated = model.generate(**batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             raise KeyError(\n\u001b[0m\u001b[0;32m    242\u001b[0m                 \u001b[1;34m\"Indexing with integers (to access backend Encoding for a given batch index) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[1;34m\"is not available when using Python based tokenizers\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "res = summarizer(chunks)\r\n",
    "res"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\liana\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21752/1126467410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m               \u001b[0mThe\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \"\"\"\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, return_tensors, return_text, clean_up_tokenization_spaces, truncation, *args, **generate_kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     def _generate(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\u001b[0m in \u001b[0;36m_generate\u001b[1;34m(self, inputs, return_tensors, return_text, clean_up_tokenization_spaces, generate_kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mgenerate_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         generations = self.model.generate(\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m             )\n\u001b[1;32m-> 1053\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1054\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1788\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   1791\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 )\n\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m         outputs = self.model(\n\u001b[0m\u001b[0;32m   1279\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m         \u001b[1;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1163\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1021\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1023\u001b[1;33m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[0;32m   1024\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[0;32m    432\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0msrc_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mattn_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Formatting Text\r\n",
    "Preprocessing: format the `dict` object into a `string`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "summary = ''\r\n",
    "for result in res:\r\n",
    "    summary += ''.join(str(val.capitalize()) + \"\\n\" for _, val in result.items())\r\n",
    "\r\n",
    "summary = summary.replace(' .', '.')\r\n",
    "summary = summary.replace(\" !\", \"!\")\r\n",
    "summary = summary.replace(\" ?\", \"?\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Results\r\n",
    "\r\n",
    "Some statistics and the final result."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_after = len(summary.split(' '))\r\n",
    "words_before = len(ARTICLE)\r\n",
    "reduced_by = (words_before - words_after) / words_before * 100\r\n",
    "\r\n",
    "print(\"Number of words in summary: \" + str(words_after))\r\n",
    "print(\"Number of words in original article: \" + str(words_before))\r\n",
    "print(\"Reduced by: \" + str(round(reduced_by, 2)) + \"%\\n\")\r\n",
    "print(summary)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words in summary: 35\n",
      "Number of words in original article: 163\n",
      "Reduced by: 78.53%\n",
      "\n",
      "The style is often described as the final expression of the baroque movement and is often described as the final expression of the style rocaille (/rkoko/, also us: /rokko/), less commonly roccoco or late baroque,\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "37833eaa7c79fc29fc64cdd65cef9244dd84f1f67a5ba8cd87f16f157512cb2c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}